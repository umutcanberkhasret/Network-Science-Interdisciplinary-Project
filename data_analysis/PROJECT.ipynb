{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4bkwQoHr9i3"
   },
   "source": [
    "# Laboratory 1: setting up Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21NaYdhRr9i7"
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNFOaZPIxyS2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TOKEN'] = 'your token here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1905,
     "status": "ok",
     "timestamp": 1642332005355,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "GjUQcJpfrecr",
    "outputId": "9499c17f-4bae-4c4a-99dc-acd97391dba7"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nwy6MeGur9i-"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8ge5EaEur9jA"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrXv204vyooY"
   },
   "source": [
    "If you need to download a library, use the following code, just specify the name of the library you need (here we downloaded emoji library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5214,
     "status": "ok",
     "timestamp": 1642327240593,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "N6RYD_oCoJ3C",
    "outputId": "deb44834-ba26-482a-bfcf-dc0b22f7c14d"
   },
   "outputs": [],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYIP9Ta4r9jR"
   },
   "source": [
    "### Set up headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKWoILn7AMzj"
   },
   "outputs": [],
   "source": [
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_buwaoAyPLM"
   },
   "outputs": [],
   "source": [
    "headers = create_headers(os.environ['TOKEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8Pb9MXWr9jd"
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUk4LQkEzbqg"
   },
   "source": [
    "Date format and other parameter explanations available here:\n",
    "\n",
    "https://developer.twitter.com/en/docs/twitter-api/premium/search-api/api-reference/premium-search#DataParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90Ukr82M_N39"
   },
   "outputs": [],
   "source": [
    "def create_url(keyword, start_date, end_date, env_label, endpoint=\"fullarchive\"):\n",
    "    search_url = \"https://api.twitter.com/1.1/tweets/search/{}.json\".format(endpoint + \"/\" + env_label)\n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword, 'fromDate': start_date, 'toDate': end_date}\n",
    "    return (search_url, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJD9pEHwAk84"
   },
   "outputs": [],
   "source": [
    "def connect_to_endpoint(url, headers, params, next_token=None):\n",
    "    if next_token is not None and next_token != '':\n",
    "        params['next'] = next_token\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Jgw8uZd0K5u"
   },
   "outputs": [],
   "source": [
    "def get_data(keyword, start_time, end_time, next_token, env_label, endpoint):\n",
    "    results = []\n",
    "    dCounter = 0\n",
    "    while next_token is not None and dCounter < 10:  #change dCounter to 10 to retrieve 1k data\n",
    "        ##this part here for one request\n",
    "        url = create_url(keyword, start_time, end_time, env_label, endpoint)\n",
    "        json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "\n",
    "        if \"results\" in json_response:\n",
    "            results.extend(json_response[\"results\"])\n",
    "        ### up until this point\n",
    "        if \"next\" in json_response:\n",
    "            next_token = json_response[\"next\"]\n",
    "            dCounter += 1\n",
    "        else:\n",
    "            next_token = None\n",
    "        time.sleep(1)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyXiwYZCl8H3"
   },
   "outputs": [],
   "source": [
    "def get_single_response(keyword, start_time, end_time, env_label, endpoint):\n",
    "    #endpoint can be fullarchive or 30day\n",
    "    results = []\n",
    "    url = create_url(keyword, start_time, end_time, env_label, endpoint)\n",
    "    json_response = connect_to_endpoint(url[0], headers, url[1])\n",
    "\n",
    "    if \"results\" in json_response:\n",
    "        results.extend(json_response[\"results\"])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSt4xdwfmHcd"
   },
   "outputs": [],
   "source": [
    "#if you are using the 30day endpoint, make sure you specify dates that are within 30day range!\n",
    "#To get small data of size \"100\" use, get_single_response\n",
    "#change the hashtags to your liking\n",
    "# with \"get_data\" we are querying for 1k data - see the definition of get_data func above\n",
    "tweets = get_data(\"(gulpanra OR JusticeforGulPanra OR StopGenocideOfTransgenders OR TransLivesMatter) lang:en\",\n",
    "                  \"202001010000\", \"202012310000\", \"\", \"NSdev\", \"fullarchive\")\n",
    "#tweets = get_single_response(\"(EndTransViolence OR BeelaCrisis OR JusticeForBijlee OR JusticeForToffi OR JusticeforGulPanra OR TransLivesMatter) lang:en\", \"202001010000\", \"202112310000\",\"NSdev\", \"fullarchive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zA-AQNsp08OX"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tQoczST6dQ8"
   },
   "source": [
    "### Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1642330931360,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "qcWGG5Rz39Gr",
    "outputId": "64389f97-d0f6-4524-c131-a1f79f585040"
   },
   "outputs": [],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1642330947666,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "Qy1AZe4O4T7C",
    "outputId": "77305af0-5353-4291-db09-8b714ae3f6be",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUGfn_G3qcLV"
   },
   "source": [
    "# Laboratory 2: working with Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6mSYSqKqh7f"
   },
   "source": [
    "First, we want to convert the data into Pandas DataFrame. This format enables us easy manipulation of the data as well as saving/loading data.\n",
    "\n",
    "Since we have our tweets saved as a list of dictionaries, we can easily convert it to DataFrame by executing the cell blow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1C940uZnWFA"
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 904
    },
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1642330958035,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "3QKr-0nRiXHa",
    "outputId": "5750c89d-9914-4afc-934d-9df3ab7c5dea",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVXP-fDrtMae"
   },
   "source": [
    "### Saving the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kmi5SprXrEOM"
   },
   "source": [
    "Once we have our Tweets as a DataFrame it is a good idea to save it on the disk. \n",
    "\n",
    "Be mindful of the fact that the storage of a Colab notebook is deleted everytime runtime is interrupted or restarted, so you need to manually download it to your computer or mount your Google Drive and save it there (this option is unavailable if you're using university's email account for Drive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1642332022585,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "PqdepSBprmvl"
   },
   "outputs": [],
   "source": [
    "path = \"Desktop\\network proje\"  #enter the path to your Drive or leave this as default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmtD5-THsUJp"
   },
   "source": [
    "We can save it as a comma-separated values file, which enables opening it in a spreadsheet editor and inspecting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1642334657198,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "ex1E8v-qrkeh"
   },
   "outputs": [],
   "source": [
    "tweets_df.to_csv(path + \"trans_case1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFcy4tKls7qD"
   },
   "source": [
    "In order to preserve datatypes, we should save it as a parquet or pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1642332039462,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "hUqdVEGksm7n"
   },
   "outputs": [],
   "source": [
    "tweets_df.to_pickle(path + \"trans_case1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H02ZoRcGtpaY"
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWhc-_nNtsnT"
   },
   "source": [
    "If you want to load the results you have previously saved, simply execute the next code, specifying the path to the file.\n",
    "\n",
    "You will need to either upload it to the Colab workspace or copy the path to the file on Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "error",
     "timestamp": 1642331030407,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "1LlenT11t_Xp",
    "outputId": "82831245-77b3-4da1-c21f-d2c30751b1dc"
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.read_pickle(\"trans_case1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 974
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1641475754729,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "RNgY35TclZC6",
    "outputId": "a95cb18e-ddc6-4c95-d618-529616b06ad2"
   },
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9ItAgz7uga9"
   },
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSvM1_xzu9Uc"
   },
   "source": [
    "In our dataframe we have the entire Tweet object. Some columns that might be of particular interest to us are: \n",
    "\n",
    "*   created_at - date when Tweet was posted\n",
    "*   id/id_str - unique Tweet identifiers\n",
    "*   text - the content of the Tweet\n",
    "*   user - information about the user who posted the Tweet\n",
    "*   retweeted_status  - information about the original Tweet\n",
    "*   quote/reply/retweet/favorite count - Tweet metrics\n",
    "*   entities - hashtags, urls, user_mentions present in Tweet\n",
    "\n",
    "We can filter the dataframe and keep only columns we are interested in. You can pick which columns you'd like to keep and put them int the column_list below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZYiG40aumbk"
   },
   "outputs": [],
   "source": [
    "#Everything is filtered below in Umut's code, no need to do it now\n",
    "\n",
    "#tweets_filtered = tweets_df.copy() #it's a good idea to work on the copy of original dataframe, so we can always go back to it if we mess something up\n",
    "#column_list = [\"created_at\", \"id_str\", \"text\", \"user\", \"retweeted_status\", \"quote_count\", \"reply_count\", \"retweet_count\", \"favorite_count\", \"entities\"]\n",
    "#tweets_filtered = tweets_filtered[column_list]\n",
    "# tweets_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 956
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1641475763262,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "qQ90m-FpxM9N",
    "outputId": "6da9745e-64fc-4e40-d17b-b274056da8ef",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "\n",
    "class CountMode(enum.Enum):\n",
    "    count_within_all_tweets = 1\n",
    "    count_within_verified_tweets = 2\n",
    "    count_within_regular_tweets = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessData(df):\n",
    "    for index, row in df.iterrows():\n",
    "        # get full_text and entities(hashtags mentions etc.) of the tweet\n",
    "        if row['truncated']:\n",
    "            tweet = {\n",
    "                \"full_text\": ast.literal_eval(row['extended_tweet'])['full_text'],\n",
    "                \"entities\": ast.literal_eval(row['extended_tweet'])['entities']\n",
    "            }\n",
    "        else:\n",
    "            # if the tweet is retweeted, this status will not be na\n",
    "            if ('retweeted_status' in row) and (not pd.isna(row['retweeted_status'])):\n",
    "                originalTweet = ast.literal_eval(row['retweeted_status'])\n",
    "                userTagName = originalTweet['user']['screen_name']\n",
    "\n",
    "                # if the text is truncated\n",
    "                if originalTweet['truncated']:\n",
    "                    tweet = {\n",
    "                        \"full_text\": \"RT @\" + userTagName + \": \" + originalTweet['extended_tweet']['full_text'],\n",
    "                        \"entities\": originalTweet['extended_tweet']['entities']\n",
    "                    }\n",
    "                else:\n",
    "                    tweet = {\n",
    "                        \"full_text\": \"RT @\" + userTagName + \": \" + originalTweet['text'],\n",
    "                        \"entities\": originalTweet['entities']\n",
    "                    }\n",
    "\n",
    "                del originalTweet\n",
    "                del userTagName\n",
    "\n",
    "            # if the tweet is original and not truncated\n",
    "            else:\n",
    "                tweet = {\n",
    "                    \"full_text\": row['text'],\n",
    "                    \"entities\": ast.literal_eval(row['entities'])\n",
    "                }\n",
    "\n",
    "        # get Username & User Tag & Location & Verification status of account\n",
    "        tweet[\"username\"] = ast.literal_eval(row['user'])['name']\n",
    "        tweet[\"screen_name\"] = ast.literal_eval(row['user'])['screen_name']\n",
    "        tweet[\"location\"] = ast.literal_eval(row['user'])['location']\n",
    "        tweet[\"is_verified\"] = ast.literal_eval(row['user'])['verified']\n",
    "\n",
    "        # get Quote & Fav & RT & Reply counts\n",
    "        tweet[\"quote_count\"] = row['quote_count']\n",
    "        tweet[\"favorite_count\"] = row['quote_count']\n",
    "        tweet[\"retweet_count\"] = row['retweet_count']\n",
    "        tweet[\"reply_count\"] = row['reply_count']\n",
    "\n",
    "        # get Tweet creation date&time\n",
    "        tweet[\"created_at\"] = row['created_at']\n",
    "\n",
    "        # get TweetID\n",
    "        tweet[\"tweet_id\"] = row['id']\n",
    "\n",
    "        tweets.append(tweet)\n",
    "\n",
    "        del tweet\n",
    "        del row\n",
    "        del index\n",
    "\n",
    "\n",
    "def countNumberOfRetweetedTweets(tweets, countMode):\n",
    "    # Separate RTs and original tweets\n",
    "    for tweet in tweets:\n",
    "        if bool(re.match(r'(RT @[\\w]+:)', tweet[\"full_text\"])):\n",
    "            if countMode == CountMode.count_within_all_tweets:\n",
    "                rts.append(tweet)\n",
    "            elif countMode == CountMode.count_within_verified_tweets:\n",
    "                verified_rts.append(tweet)\n",
    "            elif countMode == CountMode.count_within_regular_tweets:\n",
    "                regular_rts.append(tweet)\n",
    "        else:\n",
    "            if countMode == CountMode.count_within_all_tweets:\n",
    "                non_rt.append(tweet)\n",
    "            elif countMode == CountMode.count_within_verified_tweets:\n",
    "                verified_non_rt.append(tweet)\n",
    "            elif countMode == CountMode.count_within_regular_tweets:\n",
    "                regular_non_rt.append(tweet)\n",
    "        del tweet\n",
    "\n",
    "\n",
    "# Distinguish tweets according to their account verification status\n",
    "def countTweetsFromVerifiedAccounts(tweets):\n",
    "    for tweet in tweets:\n",
    "        if tweet[\"is_verified\"]:\n",
    "            tweets_from_verified_accounts.append(tweet)\n",
    "        else:\n",
    "            tweets_from_regular_accounts.append(tweet)\n",
    "\n",
    "        del tweet\n",
    "\n",
    "\n",
    "# filter locations according to city names given in listOfCities\n",
    "def filterLocations(tweets, listOfCities):\n",
    "    filtered_tweets = []\n",
    "\n",
    "    for tweet in tweets:\n",
    "        for index, city in listOfCities.iterrows():\n",
    "            if city['city'] in tweet['location']:\n",
    "                filtered_tweets.append(tweet)\n",
    "                break\n",
    "    return filtered_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../Pakistan_male/pakistan_male_case1.csv')\n",
    "df2 = pd.read_csv('../Pakistan_male/pakistan_male_case2.csv')\n",
    "df3 = pd.read_csv('../Pakistan_male/pakistan_male_case3.csv')\n",
    "tweets = []\n",
    "tweets_from_verified_accounts = []\n",
    "tweets_from_regular_accounts = []\n",
    "\n",
    "rts = []\n",
    "non_rt = []\n",
    "verified_rts = []\n",
    "regular_rts = []\n",
    "verified_non_rt = []\n",
    "regular_non_rt = []\n",
    "\n",
    "#pakistanCities = pd.read_csv('pakistanCities.csv')\n",
    "#egyptCities = pd.read_csv('egyptCities.csv')\n",
    "#dfs = [df1, df2 ,df3]\n",
    "\n",
    "# define and add the concatenated data as vars into below statement.\n",
    "dfs = pd.concat([df1, df2, df3], ignore_index=True, sort=False)\n",
    "\n",
    "#index column was not incrementing from 0 through 3000 for 3k data. So we resetted it to have an index column of 0-2999\n",
    "dfs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_final = dfs.copy()  # to work on a copy, copied the original df\n",
    "preProcessData(df_final)  # full text, column filtering are applied to the df\n",
    "\n",
    "# Iterates over the entire dataset\n",
    "countTweetsFromVerifiedAccounts(tweets)  # count of Tweets From Verified Accounts\n",
    "\n",
    "# total number of retweeted all tweets\n",
    "countNumberOfRetweetedTweets(tweets, CountMode.count_within_all_tweets)\n",
    "\n",
    "# total number of retweeted only verified tweets\n",
    "countNumberOfRetweetedTweets(tweets_from_verified_accounts, CountMode.count_within_verified_tweets)\n",
    "\n",
    "# total number of retweeted only regular tweets\n",
    "countNumberOfRetweetedTweets(tweets_from_regular_accounts, CountMode.count_within_regular_tweets)\n",
    "# df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame of whole network and in the last line, it saved it as a csv file\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweets_df\n",
    "tweets_df.to_csv(\"pakistani_male_all_tweets.csv\", index=False)  # change the name according to your case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                            full_text  \\\n0   @salsbeelll Here you go. This is an image that...   \n1   RT @MBilaloo: #JusticeForAliZafar because we h...   \n2   RT @HeavenlyKaif1: Kindest he is! \\nSuch a pur...   \n3   RT @amyy_zee: We want justice!!! #JusticeForAl...   \n4   RT @Fahad4014: Extremely disturbed to see #Usm...   \n5   Harrasers must be call out irrespect of their ...   \n6   ‚ÄòGilligan‚Äôs Island‚Äô star Dawn Wells, who playe...   \n7   Guys?  Masks. Social distance. Then ‚Äî get vacc...   \n8   ‚ÄòGilligan‚Äôs Island‚Äô star Dawn Wells dies, COVI...   \n9   It‚Äôs heartwarming seeing Mary Ann, Dawn Wells,...   \n10  RT @peeweeherman: I just saw that the actress ...   \n11  Join KBOO‚Äôs dance party DJs as they bid 2020 G...   \n12  RT @HelenBranswell: Covid strikes Gilligan's I...   \n13  How weird is it that when I learned that Gilli...   \n14  In the old KDWB studio, the walls were covered...   \n15  ‚ÄòGilligan‚Äôs Island‚Äô star Dawn Wells dies; COVI...   \n16  RT @CBSEveningNews: Actress Dawn Wells, who pl...   \n17  Actress Dawn Wells, who played Mary Ann on the...   \n18  'Gilligan's Island' star Dawn Wells dies, COVI...   \n19  RT @taymarch: https://t.co/ndh4z2cL3t Dawn Wel...   \n20  RT @Barbara_Eden: Oh Dawn,  it is never easy t...   \n21  One of the dorkiest things about me: I own eve...   \n22  It's Mary Ann and it's not even up for debate....   \n23  RT @mfrost11: Was a lucky ten year old kid to ...   \n24  RT @alexheard: My Dawn Wells \"research\" led to...   \n25  My Dawn Wells \"research\" led to this interesti...   \n26  Gilligan's Island star Dawn Wells has died fro...   \n27  Known best as the all-American girl Mary Ann o...   \n28  There is something infinitely healing in the r...   \n29  Mary Ann From 'Gilligan's Island,' Dawn Wells,...   \n\n                            username      screen_name  \\\n0                    Mahwash Ajaz üáµüá∞     mahwashajaz_   \n1                    Mahwash Ajaz üáµüá∞     mahwashajaz_   \n2                    Mahwash Ajaz üáµüá∞     mahwashajaz_   \n3                    Mahwash Ajaz üáµüá∞     mahwashajaz_   \n4                        Anees Hanif       anees_avis   \n5                       Amnah Jabeen       AmnahJPlus   \n6                      larry mcshane     lmcshanenydn   \n7                      John McNamara  johnthemcnamara   \n8               PeterboroughExaminer     PtboExaminer   \n9                       Mike Sington      MikeSington   \n10                         Sam Adams     SamuelAAdams   \n11              KBOO Community Radio             KBOO   \n12                       Calvin Ayre       CalvinAyre   \n13                   Dr. Karen James          kejames   \n14                         Dave Ryan     daveryankdwb   \n15                  The Patriot-News      PatriotNews   \n16                       News19 WLTX             WLTX   \n17                  CBS Evening News   CBSEveningNews   \n18           The Canadian Press News     CdnPressNews   \n19                   Jamison Twins üåê     PSYCHICTWINS   \n20                      Wayne Ludbey          WLudbey   \n21                   Theodore Decker  Theodore_Decker   \n22                       Ryne Dennis       RyneDennis   \n23                     Rex Chapmanüèáüèº       RexChapman   \n24                      Hank Stuever      hankstuever   \n25                        Alex Heard        alexheard   \n26                        JD ANDREWS     earthXplorer   \n27  KYW Newsradio - NOW ON 103.9 FM!     KYWNewsradio   \n28                 Northern Research         usfs_nrs   \n29                   Steven Sinofsky          stevesi   \n\n                         location  is_verified  quote_count  favorite_count  \\\n0                            None         True            0               0   \n1                            None         True            0               0   \n2                            None         True            0               0   \n3                            None         True            0               0   \n4               Karachi, Pakistan         True            0               0   \n5             Islamabad, Pakistan         True            1               1   \n6                             NYC         True            0               0   \n7                 Los Angeles, CA         True            0               0   \n8   Peterborough, Ontario, Canada         True            0               0   \n9       Los Angeles and the World         True            0               0   \n10            sam.adams@slate.com         True            0               0   \n11               Portland, OR USA         True            0               0   \n12            Antigua and Barbuda         True            0               0   \n13  Unceded Wabanaki land (Maine)         True            0               0   \n14                Minneapolis, MN         True            3               3   \n15                 Harrisburg, PA         True            0               0   \n16                   Columbia, SC         True            0               0   \n17                 üì∫ 6:30 p.m. ET         True            1               1   \n18                         Canada         True            3               3   \n19                Los Angeles, Ca         True            0               0   \n20           Melbourne Australia          True            0               0   \n21                   Columbus, OH         True            0               0   \n22                     Athens, Ga         True            0               0   \n23             Lexington/Phoenix          True            0               0   \n24                           D.C.         True            0               0   \n25                   Santa Fe, NM         True            0               0   \n26                 Miami, Fl. USA         True            0               0   \n27                   Philadelphia         True            0               0   \n28                    Madison, WI         True            0               0   \n29               Seattle ‚Ä¢ SV ‚Ä¢ üåè         True            1               1   \n\n    retweet_count  reply_count                      created_at  \\\n0               5            1  Sat Dec 12 17:51:42 +0000 2020   \n1               0            0  Sat Dec 12 17:42:46 +0000 2020   \n2               0            0  Sat Dec 12 17:41:33 +0000 2020   \n3               0            0  Sat Dec 12 17:40:09 +0000 2020   \n4               0            0  Tue Jul 27 15:33:32 +0000 2021   \n5               0            1  Tue Jul 27 15:26:51 +0000 2021   \n6               0            0  Wed Dec 30 23:59:22 +0000 2020   \n7               1            0  Wed Dec 30 23:58:47 +0000 2020   \n8               0            0  Wed Dec 30 23:58:44 +0000 2020   \n9               1            1  Wed Dec 30 23:58:13 +0000 2020   \n10              0            0  Wed Dec 30 23:58:05 +0000 2020   \n11              0            0  Wed Dec 30 23:57:21 +0000 2020   \n12              0            0  Wed Dec 30 23:55:29 +0000 2020   \n13              0            1  Wed Dec 30 23:55:18 +0000 2020   \n14              1            3  Wed Dec 30 23:54:08 +0000 2020   \n15              1            0  Wed Dec 30 23:53:16 +0000 2020   \n16              0            0  Wed Dec 30 23:53:16 +0000 2020   \n17             14            3  Wed Dec 30 23:52:43 +0000 2020   \n18              6            1  Wed Dec 30 23:52:12 +0000 2020   \n19              0            0  Wed Dec 30 23:51:43 +0000 2020   \n20              0            0  Wed Dec 30 23:51:02 +0000 2020   \n21              0            4  Wed Dec 30 23:50:56 +0000 2020   \n22              0            0  Wed Dec 30 23:50:36 +0000 2020   \n23              0            0  Wed Dec 30 23:49:59 +0000 2020   \n24              0            0  Wed Dec 30 23:49:32 +0000 2020   \n25              1            1  Wed Dec 30 23:49:12 +0000 2020   \n26              0            0  Wed Dec 30 23:47:33 +0000 2020   \n27              3            0  Wed Dec 30 23:47:01 +0000 2020   \n28              6            0  Wed Dec 30 23:47:00 +0000 2020   \n29              4            0  Wed Dec 30 23:46:33 +0000 2020   \n\n               tweet_id  \n0   1337817416886333441  \n1   1337815167887937539  \n2   1337814862945280003  \n3   1337814509470306308  \n4   1420044693199536130  \n5   1420043010415464452  \n6   1344432927141224449  \n7   1344432779904208896  \n8   1344432764947468293  \n9   1344432637994176515  \n10  1344432603798118400  \n11  1344432417076084747  \n12  1344431949394268160  \n13  1344431902871203840  \n14  1344431607156002817  \n15  1344431391283544069  \n16  1344431390989971456  \n17  1344431253660045312  \n18  1344431121493356546  \n19  1344430999128530944  \n20  1344430829750030336  \n21  1344430803988656134  \n22  1344430721423863808  \n23  1344430566397988864  \n24  1344430452069830658  \n25  1344430369253318656  \n26  1344429949919383556  \n27  1344429817282891776  \n28  1344429812417486848  \n29  1344429699724845057  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>username</th>\n      <th>screen_name</th>\n      <th>location</th>\n      <th>is_verified</th>\n      <th>quote_count</th>\n      <th>favorite_count</th>\n      <th>retweet_count</th>\n      <th>reply_count</th>\n      <th>created_at</th>\n      <th>tweet_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@salsbeelll Here you go. This is an image that...</td>\n      <td>Mahwash Ajaz üáµüá∞</td>\n      <td>mahwashajaz_</td>\n      <td>None</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>Sat Dec 12 17:51:42 +0000 2020</td>\n      <td>1337817416886333441</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RT @MBilaloo: #JusticeForAliZafar because we h...</td>\n      <td>Mahwash Ajaz üáµüá∞</td>\n      <td>mahwashajaz_</td>\n      <td>None</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sat Dec 12 17:42:46 +0000 2020</td>\n      <td>1337815167887937539</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RT @HeavenlyKaif1: Kindest he is! \\nSuch a pur...</td>\n      <td>Mahwash Ajaz üáµüá∞</td>\n      <td>mahwashajaz_</td>\n      <td>None</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sat Dec 12 17:41:33 +0000 2020</td>\n      <td>1337814862945280003</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RT @amyy_zee: We want justice!!! #JusticeForAl...</td>\n      <td>Mahwash Ajaz üáµüá∞</td>\n      <td>mahwashajaz_</td>\n      <td>None</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sat Dec 12 17:40:09 +0000 2020</td>\n      <td>1337814509470306308</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @Fahad4014: Extremely disturbed to see #Usm...</td>\n      <td>Anees Hanif</td>\n      <td>anees_avis</td>\n      <td>Karachi, Pakistan</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Tue Jul 27 15:33:32 +0000 2021</td>\n      <td>1420044693199536130</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Harrasers must be call out irrespect of their ...</td>\n      <td>Amnah Jabeen</td>\n      <td>AmnahJPlus</td>\n      <td>Islamabad, Pakistan</td>\n      <td>True</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Tue Jul 27 15:26:51 +0000 2021</td>\n      <td>1420043010415464452</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>‚ÄòGilligan‚Äôs Island‚Äô star Dawn Wells, who playe...</td>\n      <td>larry mcshane</td>\n      <td>lmcshanenydn</td>\n      <td>NYC</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:59:22 +0000 2020</td>\n      <td>1344432927141224449</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Guys?  Masks. Social distance. Then ‚Äî get vacc...</td>\n      <td>John McNamara</td>\n      <td>johnthemcnamara</td>\n      <td>Los Angeles, CA</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:58:47 +0000 2020</td>\n      <td>1344432779904208896</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>‚ÄòGilligan‚Äôs Island‚Äô star Dawn Wells dies, COVI...</td>\n      <td>PeterboroughExaminer</td>\n      <td>PtboExaminer</td>\n      <td>Peterborough, Ontario, Canada</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:58:44 +0000 2020</td>\n      <td>1344432764947468293</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>It‚Äôs heartwarming seeing Mary Ann, Dawn Wells,...</td>\n      <td>Mike Sington</td>\n      <td>MikeSington</td>\n      <td>Los Angeles and the World</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Wed Dec 30 23:58:13 +0000 2020</td>\n      <td>1344432637994176515</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RT @peeweeherman: I just saw that the actress ...</td>\n      <td>Sam Adams</td>\n      <td>SamuelAAdams</td>\n      <td>sam.adams@slate.com</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:58:05 +0000 2020</td>\n      <td>1344432603798118400</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Join KBOO‚Äôs dance party DJs as they bid 2020 G...</td>\n      <td>KBOO Community Radio</td>\n      <td>KBOO</td>\n      <td>Portland, OR USA</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:57:21 +0000 2020</td>\n      <td>1344432417076084747</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>RT @HelenBranswell: Covid strikes Gilligan's I...</td>\n      <td>Calvin Ayre</td>\n      <td>CalvinAyre</td>\n      <td>Antigua and Barbuda</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:55:29 +0000 2020</td>\n      <td>1344431949394268160</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>How weird is it that when I learned that Gilli...</td>\n      <td>Dr. Karen James</td>\n      <td>kejames</td>\n      <td>Unceded Wabanaki land (Maine)</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Wed Dec 30 23:55:18 +0000 2020</td>\n      <td>1344431902871203840</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>In the old KDWB studio, the walls were covered...</td>\n      <td>Dave Ryan</td>\n      <td>daveryankdwb</td>\n      <td>Minneapolis, MN</td>\n      <td>True</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Wed Dec 30 23:54:08 +0000 2020</td>\n      <td>1344431607156002817</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>‚ÄòGilligan‚Äôs Island‚Äô star Dawn Wells dies; COVI...</td>\n      <td>The Patriot-News</td>\n      <td>PatriotNews</td>\n      <td>Harrisburg, PA</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:53:16 +0000 2020</td>\n      <td>1344431391283544069</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>RT @CBSEveningNews: Actress Dawn Wells, who pl...</td>\n      <td>News19 WLTX</td>\n      <td>WLTX</td>\n      <td>Columbia, SC</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:53:16 +0000 2020</td>\n      <td>1344431390989971456</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Actress Dawn Wells, who played Mary Ann on the...</td>\n      <td>CBS Evening News</td>\n      <td>CBSEveningNews</td>\n      <td>üì∫ 6:30 p.m. ET</td>\n      <td>True</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14</td>\n      <td>3</td>\n      <td>Wed Dec 30 23:52:43 +0000 2020</td>\n      <td>1344431253660045312</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>'Gilligan's Island' star Dawn Wells dies, COVI...</td>\n      <td>The Canadian Press News</td>\n      <td>CdnPressNews</td>\n      <td>Canada</td>\n      <td>True</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>Wed Dec 30 23:52:12 +0000 2020</td>\n      <td>1344431121493356546</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>RT @taymarch: https://t.co/ndh4z2cL3t Dawn Wel...</td>\n      <td>Jamison Twins üåê</td>\n      <td>PSYCHICTWINS</td>\n      <td>Los Angeles, Ca</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:51:43 +0000 2020</td>\n      <td>1344430999128530944</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>RT @Barbara_Eden: Oh Dawn,  it is never easy t...</td>\n      <td>Wayne Ludbey</td>\n      <td>WLudbey</td>\n      <td>Melbourne Australia</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:51:02 +0000 2020</td>\n      <td>1344430829750030336</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>One of the dorkiest things about me: I own eve...</td>\n      <td>Theodore Decker</td>\n      <td>Theodore_Decker</td>\n      <td>Columbus, OH</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>Wed Dec 30 23:50:56 +0000 2020</td>\n      <td>1344430803988656134</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>It's Mary Ann and it's not even up for debate....</td>\n      <td>Ryne Dennis</td>\n      <td>RyneDennis</td>\n      <td>Athens, Ga</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:50:36 +0000 2020</td>\n      <td>1344430721423863808</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>RT @mfrost11: Was a lucky ten year old kid to ...</td>\n      <td>Rex Chapmanüèáüèº</td>\n      <td>RexChapman</td>\n      <td>Lexington/Phoenix</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:49:59 +0000 2020</td>\n      <td>1344430566397988864</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>RT @alexheard: My Dawn Wells \"research\" led to...</td>\n      <td>Hank Stuever</td>\n      <td>hankstuever</td>\n      <td>D.C.</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:49:32 +0000 2020</td>\n      <td>1344430452069830658</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>My Dawn Wells \"research\" led to this interesti...</td>\n      <td>Alex Heard</td>\n      <td>alexheard</td>\n      <td>Santa Fe, NM</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Wed Dec 30 23:49:12 +0000 2020</td>\n      <td>1344430369253318656</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Gilligan's Island star Dawn Wells has died fro...</td>\n      <td>JD ANDREWS</td>\n      <td>earthXplorer</td>\n      <td>Miami, Fl. USA</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:47:33 +0000 2020</td>\n      <td>1344429949919383556</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Known best as the all-American girl Mary Ann o...</td>\n      <td>KYW Newsradio - NOW ON 103.9 FM!</td>\n      <td>KYWNewsradio</td>\n      <td>Philadelphia</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:47:01 +0000 2020</td>\n      <td>1344429817282891776</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>There is something infinitely healing in the r...</td>\n      <td>Northern Research</td>\n      <td>usfs_nrs</td>\n      <td>Madison, WI</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:47:00 +0000 2020</td>\n      <td>1344429812417486848</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Mary Ann From 'Gilligan's Island,' Dawn Wells,...</td>\n      <td>Steven Sinofsky</td>\n      <td>stevesi</td>\n      <td>Seattle ‚Ä¢ SV ‚Ä¢ üåè</td>\n      <td>True</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:46:33 +0000 2020</td>\n      <td>1344429699724845057</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_from_verified_accounts_df = pd.DataFrame(tweets_from_verified_accounts)\n",
    "tweets_from_verified_accounts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                              full_text           username  \\\n0     You kidding me üöÄü§£ü§£ü§£ unconstitutional. #Justice...     ÿ≠ÿ≥ÿßŸÖ ÿßÿ≠ŸÖÿØ ÿ±ÿßŸÖ€í   \n1     @Osamarants @desibaddiee Guys, I don‚Äôt know if...     AZian ChannoüíÉüèª   \n2     RT @iLoveAli_Zafar: @_galactictony @Messifc111...          Afra Alam   \n3     @_galactictony @Messifc111 @khaismax @shradhar...     AZian ChannoüíÉüèª   \n4     RT @iLoveAli_Zafar: @cysterz @tryinaad false a...          Afra Alam   \n...                                                 ...                ...   \n2965  Disclaimer: i'm no expert. I just did some res...         üêû| T-ARA üëë   \n2966      @chipcoffey Always loved that show, RIP Dawn.       Dorinski18 .   \n2967      DAWN x Punk influence https://t.co/WSepPWqPDa         üêû| T-ARA üëë   \n2968  Dawn Wells, Mary Ann on 'Gilligan's Island,' d...  IATSE 212 Calgary   \n2969  RT @abc7george: #BREAKING - Actress Dawn Wells...   Stephen Kauffman   \n\n          screen_name              location  is_verified  quote_count  \\\n0          BrassWires      Somewhere on üåéüåçüåé        False            0   \n1      iLoveAli_Zafar  in Ali Zafar's heart        False            0   \n2      azianAfra_Alam        Kolkata, India        False            0   \n3      iLoveAli_Zafar  in Ali Zafar's heart        False            0   \n4      azianAfra_Alam        Kolkata, India        False            0   \n...               ...                   ...          ...          ...   \n2965        jindawnie                  None        False            0   \n2966       dorinski57        Fort Worth, TX        False            0   \n2967        jindawnie                  None        False            3   \n2968    Iatselocal212      Calgary, Alberta        False            0   \n2969  StephenKauffman              Bay Area        False            0   \n\n      favorite_count  retweet_count  reply_count  \\\n0                  0              0            0   \n1                  0              0            0   \n2                  0              0            0   \n3                  0              1            0   \n4                  0              0            0   \n...              ...            ...          ...   \n2965               0              0            1   \n2966               0              0            0   \n2967               3              3            1   \n2968               0              0            0   \n2969               0              0            0   \n\n                          created_at             tweet_id  \n0     Thu Dec 23 11:03:31 +0000 2021  1473972532487274498  \n1     Sat Dec 11 19:11:24 +0000 2021  1469746659026481152  \n2     Wed Nov 03 05:27:12 +0000 2021  1455768502803918851  \n3     Tue Nov 02 19:18:49 +0000 2021  1455615396917174272  \n4     Tue Nov 02 18:07:37 +0000 2021  1455597479936679941  \n...                              ...                  ...  \n2965  Wed Dec 30 23:45:34 +0000 2020  1344429454400090112  \n2966  Wed Dec 30 23:45:34 +0000 2020  1344429454299426816  \n2967  Wed Dec 30 23:45:34 +0000 2020  1344429452156149761  \n2968  Wed Dec 30 23:45:34 +0000 2020  1344429450872696836  \n2969  Wed Dec 30 23:45:32 +0000 2020  1344429442425212928  \n\n[2970 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>username</th>\n      <th>screen_name</th>\n      <th>location</th>\n      <th>is_verified</th>\n      <th>quote_count</th>\n      <th>favorite_count</th>\n      <th>retweet_count</th>\n      <th>reply_count</th>\n      <th>created_at</th>\n      <th>tweet_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>You kidding me üöÄü§£ü§£ü§£ unconstitutional. #Justice...</td>\n      <td>ÿ≠ÿ≥ÿßŸÖ ÿßÿ≠ŸÖÿØ ÿ±ÿßŸÖ€í</td>\n      <td>BrassWires</td>\n      <td>Somewhere on üåéüåçüåé</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Thu Dec 23 11:03:31 +0000 2021</td>\n      <td>1473972532487274498</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Osamarants @desibaddiee Guys, I don‚Äôt know if...</td>\n      <td>AZian ChannoüíÉüèª</td>\n      <td>iLoveAli_Zafar</td>\n      <td>in Ali Zafar's heart</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sat Dec 11 19:11:24 +0000 2021</td>\n      <td>1469746659026481152</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RT @iLoveAli_Zafar: @_galactictony @Messifc111...</td>\n      <td>Afra Alam</td>\n      <td>azianAfra_Alam</td>\n      <td>Kolkata, India</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Nov 03 05:27:12 +0000 2021</td>\n      <td>1455768502803918851</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@_galactictony @Messifc111 @khaismax @shradhar...</td>\n      <td>AZian ChannoüíÉüèª</td>\n      <td>iLoveAli_Zafar</td>\n      <td>in Ali Zafar's heart</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Tue Nov 02 19:18:49 +0000 2021</td>\n      <td>1455615396917174272</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @iLoveAli_Zafar: @cysterz @tryinaad false a...</td>\n      <td>Afra Alam</td>\n      <td>azianAfra_Alam</td>\n      <td>Kolkata, India</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Tue Nov 02 18:07:37 +0000 2021</td>\n      <td>1455597479936679941</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2965</th>\n      <td>Disclaimer: i'm no expert. I just did some res...</td>\n      <td>üêû| T-ARA üëë</td>\n      <td>jindawnie</td>\n      <td>None</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Wed Dec 30 23:45:34 +0000 2020</td>\n      <td>1344429454400090112</td>\n    </tr>\n    <tr>\n      <th>2966</th>\n      <td>@chipcoffey Always loved that show, RIP Dawn.</td>\n      <td>Dorinski18 .</td>\n      <td>dorinski57</td>\n      <td>Fort Worth, TX</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:45:34 +0000 2020</td>\n      <td>1344429454299426816</td>\n    </tr>\n    <tr>\n      <th>2967</th>\n      <td>DAWN x Punk influence https://t.co/WSepPWqPDa</td>\n      <td>üêû| T-ARA üëë</td>\n      <td>jindawnie</td>\n      <td>None</td>\n      <td>False</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Wed Dec 30 23:45:34 +0000 2020</td>\n      <td>1344429452156149761</td>\n    </tr>\n    <tr>\n      <th>2968</th>\n      <td>Dawn Wells, Mary Ann on 'Gilligan's Island,' d...</td>\n      <td>IATSE 212 Calgary</td>\n      <td>Iatselocal212</td>\n      <td>Calgary, Alberta</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:45:34 +0000 2020</td>\n      <td>1344429450872696836</td>\n    </tr>\n    <tr>\n      <th>2969</th>\n      <td>RT @abc7george: #BREAKING - Actress Dawn Wells...</td>\n      <td>Stephen Kauffman</td>\n      <td>StephenKauffman</td>\n      <td>Bay Area</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:45:32 +0000 2020</td>\n      <td>1344429442425212928</td>\n    </tr>\n  </tbody>\n</table>\n<p>2970 rows √ó 11 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame of tweets from regular accounts\n",
    "tweets_from_regular_accounts_df = pd.DataFrame(tweets_from_regular_accounts)\n",
    "tweets_from_regular_accounts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                              full_text  \\\n0     RT @iLoveAli_Zafar: @_galactictony @Messifc111...   \n1     RT @iLoveAli_Zafar: @cysterz @tryinaad false a...   \n2     RT @iLoveAli_Zafar: @Aligulpir False allegatio...   \n3     RT @iLoveAli_Zafar: @Aligulpir False allegatio...   \n4     RT @iLoveAli_Zafar: @zo_BasimStydia Because it...   \n...                                                 ...   \n1939  RT @abc7george: #BREAKING - Actress Dawn Wells...   \n1940  RT @alfranken: Sat w/Dawn Wells on a plane. Ve...   \n1941  RT @startrektour: Devastated to hear of the pa...   \n1942  RT @hapoelorient: As the #NewYearsHonours is a...   \n1943  RT @abc7george: #BREAKING - Actress Dawn Wells...   \n\n                         username      screen_name                  location  \\\n0                       Afra Alam   azianAfra_Alam            Kolkata, India   \n1                       Afra Alam   azianAfra_Alam            Kolkata, India   \n2                   M. Bilal üáµüá∞üáµüá∏         MBilaloo  Karachi, Sindh, Pakistan   \n3                    Ahmed Sheikh       AhmSheikhh                  Pakistan   \n4                       Afra Alam   azianAfra_Alam            Kolkata, India   \n...                           ...              ...                       ...   \n1939  üîÆcrystals BACK in ma bra üáØüá≤   Jamaican_candy                 Baltimore   \n1940              John McLaughlin    je_mclaughlin         New Brunswick, NJ   \n1941           Zacharias C .Moore   beliefinaction           Philadelphia,Pa   \n1942             Pinesy‚Ñ¢¬Æ Marxist   taxi_liverpool             Liverpool L13   \n1943             Stephen Kauffman  StephenKauffman                  Bay Area   \n\n      is_verified  quote_count  favorite_count  retweet_count  reply_count  \\\n0           False            0               0              0            0   \n1           False            0               0              0            0   \n2           False            0               0              0            0   \n3           False            0               0              0            0   \n4           False            0               0              0            0   \n...           ...          ...             ...            ...          ...   \n1939        False            0               0              0            0   \n1940        False            0               0              0            0   \n1941        False            0               0              0            0   \n1942        False            0               0              0            0   \n1943        False            0               0              0            0   \n\n                          created_at             tweet_id  \n0     Wed Nov 03 05:27:12 +0000 2021  1455768502803918851  \n1     Tue Nov 02 18:07:37 +0000 2021  1455597479936679941  \n2     Fri Sep 10 01:17:11 +0000 2021  1436136639898832902  \n3     Thu Sep 09 11:07:28 +0000 2021  1435922802184495106  \n4     Sun Aug 22 14:25:56 +0000 2021  1429449765184413702  \n...                              ...                  ...  \n1939  Wed Dec 30 23:45:48 +0000 2020  1344429510725423104  \n1940  Wed Dec 30 23:45:47 +0000 2020  1344429508368207875  \n1941  Wed Dec 30 23:45:41 +0000 2020  1344429482648752129  \n1942  Wed Dec 30 23:45:41 +0000 2020  1344429481809874947  \n1943  Wed Dec 30 23:45:32 +0000 2020  1344429442425212928  \n\n[1944 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>username</th>\n      <th>screen_name</th>\n      <th>location</th>\n      <th>is_verified</th>\n      <th>quote_count</th>\n      <th>favorite_count</th>\n      <th>retweet_count</th>\n      <th>reply_count</th>\n      <th>created_at</th>\n      <th>tweet_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RT @iLoveAli_Zafar: @_galactictony @Messifc111...</td>\n      <td>Afra Alam</td>\n      <td>azianAfra_Alam</td>\n      <td>Kolkata, India</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Nov 03 05:27:12 +0000 2021</td>\n      <td>1455768502803918851</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RT @iLoveAli_Zafar: @cysterz @tryinaad false a...</td>\n      <td>Afra Alam</td>\n      <td>azianAfra_Alam</td>\n      <td>Kolkata, India</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Tue Nov 02 18:07:37 +0000 2021</td>\n      <td>1455597479936679941</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RT @iLoveAli_Zafar: @Aligulpir False allegatio...</td>\n      <td>M. Bilal üáµüá∞üáµüá∏</td>\n      <td>MBilaloo</td>\n      <td>Karachi, Sindh, Pakistan</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Fri Sep 10 01:17:11 +0000 2021</td>\n      <td>1436136639898832902</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RT @iLoveAli_Zafar: @Aligulpir False allegatio...</td>\n      <td>Ahmed Sheikh</td>\n      <td>AhmSheikhh</td>\n      <td>Pakistan</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Thu Sep 09 11:07:28 +0000 2021</td>\n      <td>1435922802184495106</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @iLoveAli_Zafar: @zo_BasimStydia Because it...</td>\n      <td>Afra Alam</td>\n      <td>azianAfra_Alam</td>\n      <td>Kolkata, India</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sun Aug 22 14:25:56 +0000 2021</td>\n      <td>1429449765184413702</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1939</th>\n      <td>RT @abc7george: #BREAKING - Actress Dawn Wells...</td>\n      <td>üîÆcrystals BACK in ma bra üáØüá≤</td>\n      <td>Jamaican_candy</td>\n      <td>Baltimore</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:45:48 +0000 2020</td>\n      <td>1344429510725423104</td>\n    </tr>\n    <tr>\n      <th>1940</th>\n      <td>RT @alfranken: Sat w/Dawn Wells on a plane. Ve...</td>\n      <td>John McLaughlin</td>\n      <td>je_mclaughlin</td>\n      <td>New Brunswick, NJ</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:45:47 +0000 2020</td>\n      <td>1344429508368207875</td>\n    </tr>\n    <tr>\n      <th>1941</th>\n      <td>RT @startrektour: Devastated to hear of the pa...</td>\n      <td>Zacharias C .Moore</td>\n      <td>beliefinaction</td>\n      <td>Philadelphia,Pa</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:45:41 +0000 2020</td>\n      <td>1344429482648752129</td>\n    </tr>\n    <tr>\n      <th>1942</th>\n      <td>RT @hapoelorient: As the #NewYearsHonours is a...</td>\n      <td>Pinesy‚Ñ¢¬Æ Marxist</td>\n      <td>taxi_liverpool</td>\n      <td>Liverpool L13</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:45:41 +0000 2020</td>\n      <td>1344429481809874947</td>\n    </tr>\n    <tr>\n      <th>1943</th>\n      <td>RT @abc7george: #BREAKING - Actress Dawn Wells...</td>\n      <td>Stephen Kauffman</td>\n      <td>StephenKauffman</td>\n      <td>Bay Area</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:45:32 +0000 2020</td>\n      <td>1344429442425212928</td>\n    </tr>\n  </tbody>\n</table>\n<p>1944 rows √ó 11 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retweeted tweets\n",
    "len(rts)  # length of the rt tweets\n",
    "rts_df = pd.DataFrame(rts)\n",
    "rts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                              full_text           username  \\\n0     You kidding me üöÄü§£ü§£ü§£ unconstitutional. #Justice...     ÿ≠ÿ≥ÿßŸÖ ÿßÿ≠ŸÖÿØ ÿ±ÿßŸÖ€í   \n1     @Osamarants @desibaddiee Guys, I don‚Äôt know if...     AZian ChannoüíÉüèª   \n2     @_galactictony @Messifc111 @khaismax @shradhar...     AZian ChannoüíÉüèª   \n3     @cysterz @tryinaad false accusations, there is...     AZian ChannoüíÉüèª   \n4     @nehasaigol1 @Dawn_News Defamation cases are r...     AZian ChannoüíÉüèª   \n...                                                 ...                ...   \n1051  Dawn Wells, star of \"Gilligan's Island,\" dies ...        Donna Slash   \n1052  Disclaimer: i'm no expert. I just did some res...         üêû| T-ARA üëë   \n1053      @chipcoffey Always loved that show, RIP Dawn.       Dorinski18 .   \n1054      DAWN x Punk influence https://t.co/WSepPWqPDa         üêû| T-ARA üëë   \n1055  Dawn Wells, Mary Ann on 'Gilligan's Island,' d...  IATSE 212 Calgary   \n\n         screen_name              location  is_verified  quote_count  \\\n0         BrassWires      Somewhere on üåéüåçüåé        False            0   \n1     iLoveAli_Zafar  in Ali Zafar's heart        False            0   \n2     iLoveAli_Zafar  in Ali Zafar's heart        False            0   \n3     iLoveAli_Zafar  in Ali Zafar's heart        False            0   \n4     iLoveAli_Zafar  in Ali Zafar's heart        False            0   \n...              ...                   ...          ...          ...   \n1051     donna_slash         United States        False            0   \n1052       jindawnie                  None        False            0   \n1053      dorinski57        Fort Worth, TX        False            0   \n1054       jindawnie                  None        False            3   \n1055   Iatselocal212      Calgary, Alberta        False            0   \n\n      favorite_count  retweet_count  reply_count  \\\n0                  0              0            0   \n1                  0              0            0   \n2                  0              1            0   \n3                  0              1            0   \n4                  0              0            0   \n...              ...            ...          ...   \n1051               0              0            0   \n1052               0              0            1   \n1053               0              0            0   \n1054               3              3            1   \n1055               0              0            0   \n\n                          created_at             tweet_id  \n0     Thu Dec 23 11:03:31 +0000 2021  1473972532487274498  \n1     Sat Dec 11 19:11:24 +0000 2021  1469746659026481152  \n2     Tue Nov 02 19:18:49 +0000 2021  1455615396917174272  \n3     Tue Nov 02 18:03:06 +0000 2021  1455596343251062784  \n4     Thu Sep 23 20:50:32 +0000 2021  1441142964000997382  \n...                              ...                  ...  \n1051  Wed Dec 30 23:45:35 +0000 2020  1344429458091085824  \n1052  Wed Dec 30 23:45:34 +0000 2020  1344429454400090112  \n1053  Wed Dec 30 23:45:34 +0000 2020  1344429454299426816  \n1054  Wed Dec 30 23:45:34 +0000 2020  1344429452156149761  \n1055  Wed Dec 30 23:45:34 +0000 2020  1344429450872696836  \n\n[1056 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>username</th>\n      <th>screen_name</th>\n      <th>location</th>\n      <th>is_verified</th>\n      <th>quote_count</th>\n      <th>favorite_count</th>\n      <th>retweet_count</th>\n      <th>reply_count</th>\n      <th>created_at</th>\n      <th>tweet_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>You kidding me üöÄü§£ü§£ü§£ unconstitutional. #Justice...</td>\n      <td>ÿ≠ÿ≥ÿßŸÖ ÿßÿ≠ŸÖÿØ ÿ±ÿßŸÖ€í</td>\n      <td>BrassWires</td>\n      <td>Somewhere on üåéüåçüåé</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Thu Dec 23 11:03:31 +0000 2021</td>\n      <td>1473972532487274498</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Osamarants @desibaddiee Guys, I don‚Äôt know if...</td>\n      <td>AZian ChannoüíÉüèª</td>\n      <td>iLoveAli_Zafar</td>\n      <td>in Ali Zafar's heart</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sat Dec 11 19:11:24 +0000 2021</td>\n      <td>1469746659026481152</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@_galactictony @Messifc111 @khaismax @shradhar...</td>\n      <td>AZian ChannoüíÉüèª</td>\n      <td>iLoveAli_Zafar</td>\n      <td>in Ali Zafar's heart</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Tue Nov 02 19:18:49 +0000 2021</td>\n      <td>1455615396917174272</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@cysterz @tryinaad false accusations, there is...</td>\n      <td>AZian ChannoüíÉüèª</td>\n      <td>iLoveAli_Zafar</td>\n      <td>in Ali Zafar's heart</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Tue Nov 02 18:03:06 +0000 2021</td>\n      <td>1455596343251062784</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@nehasaigol1 @Dawn_News Defamation cases are r...</td>\n      <td>AZian ChannoüíÉüèª</td>\n      <td>iLoveAli_Zafar</td>\n      <td>in Ali Zafar's heart</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Thu Sep 23 20:50:32 +0000 2021</td>\n      <td>1441142964000997382</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1051</th>\n      <td>Dawn Wells, star of \"Gilligan's Island,\" dies ...</td>\n      <td>Donna Slash</td>\n      <td>donna_slash</td>\n      <td>United States</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:45:35 +0000 2020</td>\n      <td>1344429458091085824</td>\n    </tr>\n    <tr>\n      <th>1052</th>\n      <td>Disclaimer: i'm no expert. I just did some res...</td>\n      <td>üêû| T-ARA üëë</td>\n      <td>jindawnie</td>\n      <td>None</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Wed Dec 30 23:45:34 +0000 2020</td>\n      <td>1344429454400090112</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>@chipcoffey Always loved that show, RIP Dawn.</td>\n      <td>Dorinski18 .</td>\n      <td>dorinski57</td>\n      <td>Fort Worth, TX</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:45:34 +0000 2020</td>\n      <td>1344429454299426816</td>\n    </tr>\n    <tr>\n      <th>1054</th>\n      <td>DAWN x Punk influence https://t.co/WSepPWqPDa</td>\n      <td>üêû| T-ARA üëë</td>\n      <td>jindawnie</td>\n      <td>None</td>\n      <td>False</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Wed Dec 30 23:45:34 +0000 2020</td>\n      <td>1344429452156149761</td>\n    </tr>\n    <tr>\n      <th>1055</th>\n      <td>Dawn Wells, Mary Ann on 'Gilligan's Island,' d...</td>\n      <td>IATSE 212 Calgary</td>\n      <td>Iatselocal212</td>\n      <td>Calgary, Alberta</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wed Dec 30 23:45:34 +0000 2020</td>\n      <td>1344429450872696836</td>\n    </tr>\n  </tbody>\n</table>\n<p>1056 rows √ó 11 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not retweeted tweets, basically the remaining tweets\n",
    "len(non_rt)  # length of not rt tweets\n",
    "original_tweets_df = pd.DataFrame(non_rt)\n",
    "original_tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPgzBUJj0SZU"
   },
   "source": [
    "## Extracting words/hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CygaLHAS0nzP"
   },
   "source": [
    "There are many ways to build networks from the data we download from Twitter.\n",
    "\n",
    "One possibility is to have a bipartite network of Tweets and words/hashtags and then observe word, hashtag or word-hashtag projections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1nTCbRc0-__"
   },
   "source": [
    "### Extracting words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pGnokgK1jma"
   },
   "source": [
    "In order to extract words, we first need to clean the Tweet text. This way we will remove punctuation, hashtags/mentions/urls (they are preserved in the entity column anyway). We will also turn all letters to lowercase.\n",
    "\n",
    "You can also consider removing stopwords, removing words that are not in the english language corpora, lematizing the words, etc. I suggest you research nltk library and its possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "y5746Mq918dG"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Z8Nrv5jv1e5W"
   },
   "outputs": [],
   "source": [
    "def cleaner(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\", \"\", tweet)  # remove mentions\n",
    "    tweet = re.sub(\"#[A-Za-z0-9]+\", \"\", tweet)  # remove hashtags\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet)  # remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = str.lower(tweet)  #to lowercase\n",
    "    table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    tweet = tweet.translate(table)  # remove punctuation\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1641475773925,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "fEhs-tyy2naZ",
    "outputId": "8d6ccacf-57db-4492-b35b-0d5e0de5f655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You kidding me üöÄü§£ü§£ü§£ unconstitutional. #JusticeForAliZafar #justiceforalizafar https://t.co/o1swZHfYAj\n",
      "you kidding me üöÄü§£ü§£ü§£ unconstitutional\n"
     ]
    },
    {
     "data": {
      "text/plain": "0     here you go this is an image that was never re...\n1     harrasers must be call out irrespect of their ...\n2     ‚Äògilligan‚Äôs island‚Äô star dawn wells who played...\n3     guys masks social distance then ‚Äî get vaccinat...\n4     ‚Äògilligan‚Äôs island‚Äô star dawn wells dies covid...\n5     it‚Äôs heartwarming seeing mary ann dawn wells a...\n6     join kboo‚Äôs dance party djs as they bid 2020 g...\n7     how weird is it that when i learned that gilli...\n8     in the old kdwb studio the walls were covered ...\n9     ‚Äògilligan‚Äôs island‚Äô star dawn wells dies covid...\n10    actress dawn wells who played mary ann on the ...\n11    gilligans island star dawn wells dies covid19 ...\n12    one of the dorkiest things about me i own ever...\n13    its mary ann and its not even up for debate da...\n14    my dawn wells research led to this interesting...\n15    gilligans island star dawn wells has died from...\n16    known best as the allamerican girl mary ann on...\n17    there is something infinitely healing in the r...\n18    mary ann from gilligans island dawn wells has ...\nName: full_text, dtype: object"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# tweets_filtered[\"clean_text\"] = tweets_df[\"full_text\"].map(cleaner)\n",
    "\n",
    "# 3 different usages\n",
    "by_changing_to_df = pd.DataFrame(verified_non_rt)\n",
    "output1 = by_changing_to_df[\"full_text\"].map(cleaner)\n",
    "\n",
    "output2 = cleaner(tweets[0][\"full_text\"])\n",
    "print(tweets[0][\"full_text\"])\n",
    "print(output2)\n",
    "output1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1_lSQZ85rT_"
   },
   "source": [
    "We are going to loop through the dataframe and then through the words in the clean text. We are going to add the words as keys to dictionary and use their frequencies as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xiBKlJhV3d_S"
   },
   "outputs": [],
   "source": [
    "#initialize an empty dict\n",
    "unique_words = {}\n",
    "for row in tweets_filtered.clean_text:\n",
    "    for word in row.split(\" \"):\n",
    "        #if the word is encountered for the first time add to dict as key and set its value to 0\n",
    "        unique_words.setdefault(word, 0)\n",
    "        #increase the value (i.e the count) of the word by 1 every time it is encountered\n",
    "        unique_words[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1641475792443,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "8k7riE1z7F6r",
    "outputId": "cce7212b-5934-4ffc-a44f-564ba16bf119"
   },
   "outputs": [],
   "source": [
    "#remove empty word\n",
    "unique_words.pop(\"\")\n",
    "#remove word 'rt'\n",
    "unique_words.pop(\"rt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVYvDBQu57If"
   },
   "source": [
    "We can inspect the words as a dataframe. \n",
    "\n",
    "\n",
    "You can always save this dataframe as .csv for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1641475796119,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "_xI5aGQM53u4",
    "outputId": "c81c1993-af77-4cce-bb8f-4beda4a36128"
   },
   "outputs": [],
   "source": [
    "#In the last line, it saves word count df as csv file. It's better to save it so that maybe we'll use it later for the presentation\n",
    "uw_df = pd.DataFrame.from_dict(unique_words, orient='index').reset_index()\n",
    "print(uw_df)\n",
    "uw_df.rename(columns={'index': 'Word', 0: 'Count'}, inplace=True)\n",
    "uw_df.sort_values(by=['Count'], ascending=False, inplace=True)\n",
    "uw_df\n",
    "uw_df.to_csv(\"full_network_word_count.csv\", index=False)  # change the name to your liking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4R-j-FN7Rgo"
   },
   "source": [
    "### Extracting the hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8SfJwmf9GU2"
   },
   "source": [
    "We are going to loop through the dataframe and then through the hashtags in the entities. We are going to add the hashtags as keys to dictionary and use their frequencies as values. At the same time, we are going to save them in a list and add them to a separate column to facilitate our future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1641475805775,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "TEMUaIdCBlc_",
    "outputId": "213935de-889d-4e60-de67-c34545919ab2"
   },
   "outputs": [],
   "source": [
    "# no need to run this cell. We already have screen_name column by this point\n",
    "\n",
    "\"\"\"\n",
    "#TASK-1\n",
    "\n",
    "sc_name = {}\n",
    "tweets_filtered[\"screen_name\"] = \"\"\n",
    "\n",
    "for idx, row in tweets_filtered.iterrows():\n",
    "  screen_name_list = []\n",
    "  for user_mentions in row[\"entities\"][\"user_mentions\"]:\n",
    "    sc_name.setdefault(user_mentions['screen_name'], 0)\n",
    "    sc_name[user_mentions[\"screen_name\"]] += 1\n",
    "    screen_name_list.append(user_mentions[\"screen_name\"])\n",
    "  tweets_filtered.at[idx,\"screen_names\"] = screen_name_list\n",
    "sc_name\n",
    "\n",
    "sc_df = pd.DataFrame.from_dict(sc_name, orient='index').reset_index()\n",
    "sc_df.rename(columns = {'index':'Username', 0:'Count'}, inplace=True)\n",
    "sc_df.sort_values(by=['Count'], ascending=False, inplace=True)\n",
    "sc_df\n",
    "#END OF TASK-1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'#JusticeForAliZafar': 716,\n '#justiceforalizafar': 99,\n '#istandwithAliZafar': 11,\n '#justiceForAliZafar': 2,\n '#JusticeForJohhnyDepp': 2,\n '#MeToo': 346,\n '#MenToo': 66,\n '#AliZafarisinnocent': 8,\n '#IstandwithAliZafar': 3,\n '#law': 6,\n '#Pakistan': 27,\n '#JusticeForJohnnyDepp': 91,\n '#AliZafar': 193,\n '#JusticeForUsmanMukhtar': 4,\n '#StayStrongUsmanMukhtar': 983,\n '#stopbullying': 2,\n '#JusticeforAliZafar': 169,\n '#StopBullying': 3,\n '#Falseallegation': 2,\n '#FalseAllegations': 17,\n '#AZians': 12,\n '#Haters': 3,\n '#maheenghani': 5,\n '#metoo': 11,\n '#falseallegation': 5,\n '#JusticeForAlizafar': 1,\n '#IStandWithAliZafar': 2,\n '#iStandWithAliZafar': 20,\n '#Coronaviruspakistan': 35,\n '#LeenaGhani': 1,\n '#FaceTheCourtMeeshaShafi': 8,\n '#Alizafar': 12,\n '#Mentoo': 8,\n '#Meera': 2,\n '#MeeshaShafi': 25,\n '#AliZafarprideofpakistan': 2,\n '#SheLIED': 1,\n '#Karma': 1,\n '#Metoo': 18,\n '#Twitter': 3,\n '#AmberHeard': 9,\n '#iffatOmar': 2,\n '#WOMEN': 1,\n '#IffatOmar': 2,\n '#NoorJahan': 1,\n '#NusratFatehAliKhan': 1,\n '#JusticeforAsifIqbal': 1,\n '#cyberbullying': 1,\n '#JUSTICEFORALIZAFAR': 4,\n '#SayNoToFalseAllegations': 1,\n '#JusticeforJohnnyDepp': 1,\n '#JohnnyDepp': 1,\n '#Lahore': 2,\n '#truthprevailed': 4,\n '#facethecourtmeeshashafi': 47,\n '#falseallegations': 1,\n '#justiceforAliZafar': 3,\n '#AliZafarIsinnocent': 23,\n '#alizafar': 65,\n '#ALIZAFAR': 3,\n '#ISUPPORTALIZAFAR': 2,\n '#IstandWithAliZafar': 2,\n '#AliZafarisInnocent': 5,\n '#AliZafarIsInnocent': 2,\n '#alizafarisinnocent': 2,\n '#staystrong': 1,\n '#yourfansstandswithyou': 1,\n '#SayNoToLiars': 2,\n '#julie': 2,\n '#court': 2,\n '#NighatDad': 5,\n '#ShahzadIqbal': 5,\n '#geonews': 5,\n '#fia': 5,\n '#JohnnyDepps': 10,\n '#Timesup': 8,\n '#IstandwithAlizafar': 1,\n '#StopabusingFeminisim': 1,\n '#istandwithAlizafar': 1,\n '#banmeeshashafi': 69,\n '#whyshouldmenalwayssuffer': 1,\n '#nomoremeetoo': 1,\n '#bhaeehazirhai': 1,\n '#boycottmeesha': 39,\n '#facethecourt': 2,\n '#BanMeeshaShafi': 19,\n '#cokestudio': 1,\n '#meeshashafi': 1,\n '#facecourtmeesha': 1,\n '#boycottmeeshashafi': 19,\n '#facecourtmeeshashafi': 15,\n '#StandForAliZafar': 3,\n '#FaceTheCourtMeesha': 3,\n '#I_condemn_Attack_on_Iqrar': 7,\n '#I_Condemn_Attack_on_Iqrar': 1,\n '#BoycottMeeshaShafi': 10,\n '#FacetheCourtMeeshaSahafi': 1,\n '#worldwide': 2,\n '#AZian': 2,\n '#rockstar': 5,\n '#FacetheCourtMeeshaShafi': 1,\n '#Stand': 1,\n '#AmazonInPakistan': 6,\n '#Banmeeshashafi': 15,\n '#ŸÅÿ∂ŸÑ_ÿßŸÑÿ±ÿ≠ŸÖÿßŸÜ_⁄©€í_ÿßÿ´ÿßÿ´€í': 1,\n '#PDMJalsa_RiskingLives': 1,\n '#Aitraz': 2,\n '#NotAllMen': 139,\n '#EndFemicide': 65,\n '#NoorNeedsJustice': 70,\n '#ŸàÿßŸÑÿØ€åŸÜ_ŸÖÿπÿßÿ¥ÿ±ÿ™€å_ÿ®⁄Øÿß⁄ë_ÿ±Ÿà⁄©€å⁄∫': 62,\n '#UsmanMukhtar': 288,\n '#ZahirJaffar': 70,\n '#SardarTanveerExposed': 83,\n '#YumnaZaidi': 72,\n '#exams2021': 61,\n '#Taliban': 25,\n '#JusticeForNaseemBibi': 58,\n '#YesAllMen': 28,\n '#NCOC': 26,\n '#Iraq': 25,\n '#hajj': 25,\n '#Kandhar': 25,\n '#NoorMukaddam': 13,\n '#JusticeForQuratulainAnnie': 11,\n '#sunglassestwitter': 11,\n '#TalhaTalib': 11,\n '#HangRapist': 11,\n '#staystrongusmanmukhtar': 16,\n '#Mukhtar': 2,\n '#FIA': 2,\n '#cancelExamsSaveStudent': 2,\n '#ShafqatMahmood': 5,\n '#CristianoRonaldo': 4,\n '#MentalHealthMatters': 1,\n '#Mentalhealth': 1,\n '#yesallmen': 10,\n '#usmanmukhtar': 1,\n '#staystrongUsmanMukhtar': 1,\n '#Social': 8,\n '#Media': 8,\n '#Cyber': 8,\n '#Harassing': 8,\n '#Socialmedia': 8,\n '#Platforms': 8,\n '#Technology': 8,\n '#Bullying': 2,\n '#Harassment': 2,\n '#abuseralert': 1,\n '#women': 1,\n '#mentalhealth': 1,\n '#socialmedia': 1,\n '#JusticeForNoormukadam': 9,\n '#MahiraKhan': 1,\n '#ZaraNoorAbbas': 1,\n '#TheCurrent': 1,\n '#professional': 1,\n '#Facebookadscampaignmanager': 1,\n '#Fiverr': 1,\n '#facebookads': 1,\n '#facebookadsmanager': 1,\n '#fbadscampign': 1,\n '#facebookadvertising': 1,\n '#fbadsmanager': 1,\n '#NotAllmen': 2,\n '#Exams2021': 25,\n '#JusticeForSaima': 1,\n '#SoreLoserMaryam': 1,\n '#Khasha': 1,\n '#hangrapist': 3,\n '#ImranKhan': 3,\n '#Muhammadadnanraza': 1,\n '#UsmanMuktar': 1,\n '#feminist': 4,\n '#justicefornaseembibi': 2,\n '#Churails': 1,\n '#harpaltv92': 4,\n '#ArrestAbdulSalamDawood': 11,\n '#Madina': 1,\n '#JusticeForNaseem': 6,\n '#Shafqatmehmood': 3,\n '#exam2021': 1,\n '#SupportSmallBusinesses': 2,\n '#Shafqat_NoMore': 1,\n '#AuratMarch': 1,\n '#Arrested': 1,\n '#FolloForFolloBack': 1,\n '#IsraeliTerrorism': 1,\n '#ShehrozeKashif': 2,\n '#MountEverest': 2,\n '#notallwomen': 2,\n '#ÿ∫ÿØ€åÿ±_ÿ±Ÿàÿ≤Ÿêÿ™⁄©ŸÖ€åŸÑ_ÿØ€åŸÜ': 2,\n '#AliSadpara': 2,\n '#MardMarch': 4,\n '#EndMenicide': 1,\n '#ZahirJaffer': 1,\n '#allwomen': 1,\n '#rape': 2,\n '#Karachi': 1,\n '#lockdown': 1,\n '#IamManAndiWillProtectWomen': 1,\n '#Our_Martyrs_Our_Pride': 1,\n '#IamManAndiProtectWomen': 1,\n '#StaystrongUsmanMukhtar': 2,\n '#feminists': 1,\n '#MeraJismMeriMarzi': 1,\n '#RIPDawn': 5,\n '#Finnrey': 1,\n '#LinseydawnMcKenzie': 1,\n '#RIPDawnWells': 33,\n '#DawnWells': 30,\n '#COVID19': 13,\n '#BREAKING': 65,\n '#RIP': 26,\n '#NBCCT': 1,\n '#GilligansIsland': 35,\n '#MaryAnn': 9,\n '#GGACP': 1,\n '#gilligansisland': 6,\n '#sagaftramember': 5,\n '#Taiji': 1,\n '#TwipodsParanomal': 1,\n '#2020worstyear': 1,\n '#Nostalgia': 1,\n '#actress': 1,\n '#1960s': 1,\n '#news': 1,\n '#Trending': 1,\n '#trendingnews': 1,\n '#DawnWellsRIP': 6,\n '#dawnwells': 3,\n '#quoteoftheday': 1,\n '#TheView': 1,\n '#RIPMaryAnn': 3,\n '#kboo': 1,\n '#CovidIsContagiousAndDeadly': 1,\n '#maryann': 3,\n '#Cinema': 2,\n '#film': 2,\n '#FilmTwitter': 2,\n '#movie': 2,\n '#NewYearsHonours': 7,\n '#DonaldTrumpKilledMaryAnn': 1,\n '#TrumpVirus': 1,\n '#Fuck2020': 1,\n '#KFINews': 4,\n '#Exouler': 2,\n '#Trancemission': 2,\n '#Radiorecord': 2,\n '#Bestof2020': 2,\n '#TranceFamily': 2,\n '#TranceMusic': 2,\n '#upliftingtrance': 2,\n '#trance': 2,\n '#paleo': 1,\n '#fantasy': 1,\n '#5stars': 1,\n '#SPShow': 1,\n '#pop_a': 1,\n '#Âè§ÂÆ∂Ê≠£‰∫®': 1,\n '#„Ç∏„Çß„Ç∏„É•„É≥': 1,\n '#tomorrowspaperstoday': 1,\n '#COVID': 3,\n '#nbcnightlynews': 1,\n '#AskSaiqa': 1,\n '#IHateCOVID': 1,\n '#IH2020': 1,\n '#2021makeawish': 2,\n '#JoshHawley': 1,\n '#pokemon': 1,\n '#sinnoh': 1,\n '#KidVicious': 1,\n '#DawnJohnson': 2,\n '#DJEMF': 1,\n '#TinaLouise': 1,\n '#ForeverYoung': 1,\n '#Coronavirus': 1,\n '#Outbreak': 1,\n '#Pandemic': 1,\n '#GetWell': 1,\n '#NotWorthTheRisk': 1,\n '#HealthFirst': 1,\n '#HealthMatters': 1,\n '#StayHome': 2,\n '#StaySafe': 1,\n '#CelebrityPassing': 1,\n '#Good2021': 1,\n '#rip': 1,\n '#epicfantasy': 1,\n '#RipMaryAnn': 2,\n '#GHQ': 1,\n '#PDM': 1,\n '#MaryAnnRIP': 2,\n '#Bitcoin': 3,\n '#amazon': 3,\n '#deals': 3,\n '#discount': 3,\n '#offer': 3,\n '#YouTube': 2,\n '#Twitch': 2,\n '#„É¨„Ç∏„Çß„É≥„Ç∫': 2,\n '#DBLegends': 2,\n '#DragonBall': 2,\n '#mobilegaming': 2,\n '#„Éâ„É©„Ç¥„É≥„Éú„Éº„É´„É¨„Ç∏„Çß„É≥„Ç∫': 2,\n '#GoldenDawnTrial': 1,\n '#Œ¥ŒµŒΩ_ŒµŒπŒΩŒ±Œπ_Œ±Œ∏œâŒøŒπ': 1,\n '#WearAMask': 1,\n '#Melfest': 1,\n '#fuck2020': 1,\n '#imoverthis': 1,\n '#affirmation': 1,\n '#YearInReview': 1,\n '#OpenAccess': 1,\n '#Plan_S': 1,\n '#StephensCollege': 1,\n '#Maryann': 1,\n '#quote': 2,\n '#TwipodsMinority': 1,\n '#Twipods': 1,\n '#ALDUBatADN285Weeks': 1,\n '#SmartNews': 1,\n '#AndTheRestInPeace': 1,\n '#ginger': 1,\n '#condolences': 1,\n '#Covid': 1,\n '#covid19': 1,\n '#bitmex': 1,\n '#Ëá™ÂãïÁõ∏‰∫í„Éï„Ç©„É≠„Éº': 1,\n '#TeamFollowback': 1,\n '#Dawn': 1,\n '#Wells': 1,\n '#Joe': 1,\n '#Clark': 1,\n '#Boston': 1,\n '#Dynamics': 1,\n '#500ADay': 1,\n '#RT‰ºÅÁîª': 1,\n '#TFW': 1,\n '#1000ADay': 1,\n '#Áõ∏‰∫íRT': 1,\n '#FollowNGain': 1,\n '#TFB': 1,\n '#Âõ∫ÂÆö„ÉÑ„Ç§„Éº„ÉàRT': 1,\n '#dawnwalk': 1,\n '#sunup': 1,\n '#lumixlx100': 1,\n '#sunrise': 1,\n '#lx100': 1,\n '#takenbak': 1,\n '#takenbakimages': 1,\n '#urban': 1,\n '#landscape': 1,\n '#creative': 1,\n '#photography': 1,\n '#sussex': 1,\n '#eastsussex': 1,\n '#bexhill': 1,\n '#bexhillonsea': 1}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_hashtags = {}\n",
    "\n",
    "df_to_check = pd.DataFrame(tweets)\n",
    "# exp_df = verified_non_rt\n",
    "df_to_check[\"hashtags\"] = \"\"\n",
    "\n",
    "for idx, row in df_to_check.iterrows():\n",
    "    hashtag_list = []\n",
    "    for hashtag in row[\"entities\"][\"hashtags\"]:\n",
    "        unique_hashtags.setdefault(\"#\" + hashtag[\"text\"], 0)\n",
    "        unique_hashtags['#' + hashtag[\"text\"]] += 1\n",
    "        hashtag_list.append(hashtag[\"text\"])\n",
    "    df_to_check.at[idx, \"hashtags\"] = hashtag_list\n",
    "\n",
    "unique_hashtags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCb7arJqUXOu"
   },
   "outputs": [],
   "source": [
    "uh_df = pd.DataFrame.from_dict(unique_hashtags, orient='index').reset_index()\n",
    "uh_df.rename(columns={'index': 'Hashtag', 0: 'Count'}, inplace=True)\n",
    "uh_df.sort_values(by=['Count'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1641475861140,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "31Ydx_RbWSGc",
    "outputId": "34bfc0b7-26a6-453e-ac9a-cc42a30ab758"
   },
   "outputs": [],
   "source": [
    "#In the last line, it saves hashtag count df as csv file. It's better to save it so that maybe we'll use it later for the presentation\n",
    "uh_df\n",
    "uh_df.to_csv(\"full_network_hashtag_count.csv\", index=False)  # change the name to your liking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPaVj1tj9Uw6"
   },
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt2co2ep9YCd"
   },
   "source": [
    "We are going to use the networkx library, which is a Python library that enables network science analysis of the data.\n",
    "\n",
    "We are going to use it to create our network and extract edgelist from it, since we can easily import it to Gephi (a software we are going to see in visualization labs).\n",
    "\n",
    "However, it offers implemented algorithms for analysis (for example PageRank) that you can use out-of-box to analyze your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnd62ng6-GLW"
   },
   "source": [
    "But first, we will loop through our dataframe and connect words and hashtags if they appear together in the same Tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BooMyc6-1JWa"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adLbCz86M7SR"
   },
   "outputs": [],
   "source": [
    "uh = unique_hashtags.keys()\n",
    "uw = unique_words.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1641475877898,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "LZItEvJqKVE5",
    "outputId": "24b317f5-f173-46c3-9215-fa7aef439e39"
   },
   "outputs": [],
   "source": [
    "# No need to run this cell\n",
    "\n",
    "\"\"\"\n",
    "#SELEN\n",
    "sc=sc_name.keys()\n",
    "sc\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1641476573042,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "UHuQ3rRXOA5_",
    "outputId": "092a9bcf-4595-4e5d-bea0-b82794f69278"
   },
   "outputs": [],
   "source": [
    "#It creates pairs from all words.\n",
    "# From this cell on, we will create 3 different networks:\n",
    "# Network1 = words+hashtags\n",
    "#Network2 = words only\n",
    "#Network3 = hashtags only\n",
    "#This cell is for Network1\n",
    "network = {}\n",
    "network_key = 0\n",
    "for index, row in tweets_filtered.iterrows():\n",
    "    #hashtags extracted from Tweet do not have the # sign in front of them but we will add it to differentiate hashtags from words\n",
    "    combined_list = ['#' + hashtag for hashtag in row[\"hashtags\"] if '#' + hashtag in unique_hashtags] + [word for word\n",
    "                                                                                                          in str.split(\n",
    "            row[\"clean_text\"], \" \") if word in uw]\n",
    "    #itertool product creates Cartesian product of each element in the combined list\n",
    "    for pair in itertools.product(combined_list, combined_list):\n",
    "        #exclude self-loops and count each pair only once because our graph is undirected and we do not take self-loops into account\n",
    "        if pair[0] != pair[1] and not (pair[::-1] in network):\n",
    "            network.setdefault(pair, 0)\n",
    "            network[pair] += 1\n",
    "network_df = pd.DataFrame.from_dict(network, orient=\"index\")\n",
    "network_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1641477104201,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "xN92q-Xp8nHN",
    "outputId": "17002944-6569-4c1b-e072-9da8601194cc"
   },
   "outputs": [],
   "source": [
    "#This cell is for Network2\n",
    "# NETWORK OF ONLY WORDS\n",
    "networkWords = {}\n",
    "networkWords_key = 0\n",
    "for index, row in tweets_filtered.iterrows():\n",
    "    word_list = [word for word in str.split(row[\"clean_text\"], \" \") if word in uw]\n",
    "    #itertool product creates Cartesian product of each element in the word list\n",
    "    for pair in itertools.product(word_list, word_list):\n",
    "        #exclude self-loops and count each pair only once because our graph is undirected and we do not take self-loops into account\n",
    "        if pair[0] != pair[1] and not (pair[::-1] in networkWords):\n",
    "            networkWords.setdefault(pair, 0)\n",
    "            networkWords[pair] += 1\n",
    "networkWords_df = pd.DataFrame.from_dict(networkWords, orient=\"index\")\n",
    "networkWords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1641476701687,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "l2FhvB7i8oVL",
    "outputId": "0f033592-7930-4d81-b983-c2e5a0823253"
   },
   "outputs": [],
   "source": [
    "#This cell is for Network3\n",
    "# NETWORK OF ONLY HASHTAGS\n",
    "networkHashtags = {}\n",
    "networkHashtags_key = 0\n",
    "for index, row in tweets_filtered.iterrows():\n",
    "    #hashtags extracted from Tweet do not have the # sign in front of them but we will add it to differentiate hashtags from words\n",
    "    hashtag_list = ['#' + hashtag for hashtag in row[\"hashtags\"] if '#' + hashtag in unique_hashtags]\n",
    "    #itertool product creates Cartesian product of each element in the word list\n",
    "    for pair in itertools.product(hashtag_list, hashtag_list):\n",
    "        #exclude self-loops and count each pair only once because our graph is undirected and we do not take self-loops into account\n",
    "        if pair[0] != pair[1] and not (pair[::-1] in networkHashtags):\n",
    "            networkHashtags.setdefault(pair, 0)\n",
    "            networkHashtags[pair] += 1\n",
    "networkHashtags_df = pd.DataFrame.from_dict(networkHashtags, orient=\"index\")\n",
    "networkHashtags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1641476711598,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "8uThrYGHSdEe",
    "outputId": "00a98b59-7de9-4ed6-e75e-721c45015976"
   },
   "outputs": [],
   "source": [
    "#This cell is for Network1\n",
    "network_df.reset_index(inplace=True)\n",
    "network_df.columns = [\"pair\", \"weight\"]\n",
    "network_df.sort_values(by=\"weight\", inplace=True, ascending=False)\n",
    "network_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1641477110323,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "PpfdMCeq9DKw",
    "outputId": "baeb7c2a-9ebf-4f51-b29a-63de01d774e0"
   },
   "outputs": [],
   "source": [
    "#This cell is for Network2\n",
    "# FOR WORD NETWORK\n",
    "networkWords_df.reset_index(inplace=True)\n",
    "networkWords_df.columns = [\"pair\", \"weight\"]\n",
    "networkWords_df.sort_values(by=\"weight\", inplace=True, ascending=False)\n",
    "networkWords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1641477146234,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "iZ_Eqf4d9Kyo",
    "outputId": "d1a56d7e-c80c-47b0-dccf-5b0b20ad7f9f"
   },
   "outputs": [],
   "source": [
    "#This cell is for Network3\n",
    "# FOR HASHTAG NETWORK\n",
    "networkHashtags_df.reset_index(inplace=True)\n",
    "networkHashtags_df.columns = [\"pair\", \"weight\"]\n",
    "networkHashtags_df.sort_values(by=\"weight\", inplace=True, ascending=False)\n",
    "networkHashtags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJvNvzGXy8Kg",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This cell is for Network1\n",
    "#to get weighted graph we need a list of 3-element tuplels (u,v,w) where u and v are nodes and w is a number representing weight\n",
    "up_weighted = []\n",
    "for edge in network:\n",
    "    #we can filter edges by weight by uncommenting the next line and setting desired weight threshold\n",
    "    #if(network[edge])>1:\n",
    "    up_weighted.append((edge[0], edge[1], network[edge]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(up_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YY9YphU9WbK"
   },
   "outputs": [],
   "source": [
    "#This cell is for Network2 & Network3\n",
    "# list of 3-element tuples for word and hastag networks\n",
    "up_weighted_words = []\n",
    "for edge in networkWords:\n",
    "    #we can filter edges by weight by uncommenting the next line and setting desired weight threshold\n",
    "    #if(network[edge])>1:\n",
    "    up_weighted_words.append((edge[0], edge[1], networkWords[edge]))\n",
    "\n",
    "G_words = nx.Graph()\n",
    "G_words.add_weighted_edges_from(up_weighted_words)  # words graph\n",
    "\n",
    "#to get weighted graph we need a list of 3-element tuplels (u,v,w) where u and v are nodes and w is a number representing weight\n",
    "up_weighted_hashtags = []\n",
    "for edge in networkHashtags:\n",
    "    #we can filter edges by weight by uncommenting the next line and setting desired weight threshold\n",
    "    #if(network[edge])>1:\n",
    "    up_weighted_hashtags.append((edge[0], edge[1], networkHashtags[edge]))\n",
    "\n",
    "G_hashtags = nx.Graph()\n",
    "G_hashtags.add_weighted_edges_from(up_weighted_hashtags)  # hashtags graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 41665,
     "status": "ok",
     "timestamp": 1641477366035,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "PhfOH64iajWZ",
    "outputId": "0379e2e5-9dd4-4c51-db5e-c50cae42d036"
   },
   "outputs": [],
   "source": [
    "# No need to run this cell, we'll use Gephi for visualization anyways\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "nx.draw(G, with_labels=True, node_size=1.5, alpha=0.3, arrows=True)\n",
    "plt.show()\n",
    "nx.draw(G, with_labels=True)\n",
    "plt.show()\n",
    "\n",
    "### ploting words network\n",
    "nx.draw(G_words, with_labels=True, node_size=1.5, alpha=0.3, arrows=True)\n",
    "plt.show()\n",
    "nx.draw(G_words, with_labels=True)\n",
    "plt.show()\n",
    "\n",
    "### ploting hashtags network\n",
    "nx.draw(G_hashtags, with_labels=True, node_size=1.5, alpha=0.3, arrows=True)\n",
    "plt.show()\n",
    "nx.draw(G_hashtags, with_labels=True)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1641477443087,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "eSneLIqZNvt1",
    "outputId": "bc3acef6-8a04-4d3e-db02-8b960fb3f16b"
   },
   "outputs": [],
   "source": [
    "# This cell is for Network1\n",
    "# WORDS&HASHTAGS NETWORK NODES&EDGES\n",
    "print(len(G.nodes()))  # nodes=each word in the texts\n",
    "print(len(G.edges()))  # edges=pairs for each word\n",
    "#G.edges\n",
    "#G.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1641477467236,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "yfj-H9U49n02",
    "outputId": "1d449394-5fa5-46fc-ae58-3f65a64c95d1"
   },
   "outputs": [],
   "source": [
    "# This cell is for Network2 & Network3\n",
    "\n",
    "#WORDS NETWORK NODES&EDGES\n",
    "print(len(G_words.nodes()))\n",
    "print(len(G_words.edges()))\n",
    "#HASHTAGS NETWORK NODES&EDGES\n",
    "print(len(G_hashtags.nodes()))\n",
    "print(len(G_hashtags.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1641477541330,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "b3avJtbl-A5q",
    "outputId": "72e92610-f346-45ed-989f-fc6e13e84d05"
   },
   "outputs": [],
   "source": [
    "#In this cell, we rank the nodes using Pagerank function and print the top20 nodes with the highest pageranks\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "pr = nx.pagerank(G, alpha=0.9)  # we ranked the nodes of Network1 with pagerank\n",
    "\n",
    "# Let's print the top-20 pairs\n",
    "c = Counter(pr)\n",
    "top_20_network = c.most_common(20)\n",
    "print(top_20)\n",
    "print(\"********************\")\n",
    "\n",
    "pr_word = nx.pagerank(G_words, alpha=0.9)  # we ranked the nodes of Network2 with pagerank\n",
    "\n",
    "# Let's print the top-20 pairs\n",
    "c = Counter(pr_word)\n",
    "top_20_word = c.most_common(20)\n",
    "print(top_20_word)\n",
    "print(\"********************\")\n",
    "\n",
    "pr_hashtag = nx.pagerank(G_hashtags, alpha=0.9)  # we ranked the nodes of Network3 with pagerank\n",
    "\n",
    "# Let's print the top-20 pairs\n",
    "c = Counter(pr_hashtag)\n",
    "top_20_hashtag = c.most_common(20)\n",
    "print(top_20_hashtag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj3CwR5Cy8Kk"
   },
   "source": [
    "#### SAVE EDGELIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFtpm869ONHg"
   },
   "outputs": [],
   "source": [
    "# Now we're going to save edgelists and nodelists to use for Gephi later\n",
    "# Change the names according to your case\n",
    "filename1 = \"./network_edgelist_trans.csv\"\n",
    "filename2 = \"./word_edgelist_trans.csv\"\n",
    "filename3 = \"./hashtag_edgelist_trans.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTmGSBc3y8Kn"
   },
   "outputs": [],
   "source": [
    "nx.write_weighted_edgelist(G, filename1, delimiter=\",\")  # Graph name must be changed!!\n",
    "nx.write_weighted_edgelist(G_words, filename2, delimiter=\",\")  # Graph name must be changed!!\n",
    "nx.write_weighted_edgelist(G_hashtags, filename3, delimiter=\",\")  # Graph name must be changed!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GlboURoYy8Kp"
   },
   "outputs": [],
   "source": [
    "# If this cell doesn't work in your device, no worries you can skip it\n",
    "#add header with appropriate column names (works on collab and Linux/Mac(?))\n",
    "!sed -i.bak 1i\"Source,Target,Weight\"./ network_edgelist_trans.csv  # Graph name must be changed!!\n",
    "!sed -i.bak 1i\"Source,Target,Weight\"./ word_edgelist_trans.csv  # Graph name must be changed!!\n",
    "!sed -i.bak 1i\"Source,Target,Weight\"./ hashtag_edgelist_trans.csv  # Graph name must be changed!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5oT2lSry8Kq"
   },
   "source": [
    "### Create Node List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1641478010814,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "lpef5RKvUu_w",
    "outputId": "ad0da51d-ab08-408d-e3a2-32323a5de591"
   },
   "outputs": [],
   "source": [
    "# This creates a csv file of nodes for Network2\n",
    "word_nodes = pd.DataFrame.from_dict(unique_words, orient=\"index\")\n",
    "word_nodes.reset_index(inplace=True)\n",
    "word_nodes[\"Label\"] = word_nodes[\"index\"]\n",
    "word_nodes.rename(columns={\"index\": \"Id\", 0: \"delete\"}, inplace=True)\n",
    "word_nodes = word_nodes.drop(columns=['delete'])\n",
    "\n",
    "word_nodes\n",
    "word_nodes.to_csv(\"word_nodelist_trans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "executionInfo": {
     "elapsed": 427,
     "status": "ok",
     "timestamp": 1641478017841,
     "user": {
      "displayName": "Mustafa Algun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8neAD8pWo4clblXdS6rgHQO_PTZV38FEIy3Lh=s64",
      "userId": "02151313343513449482"
     },
     "user_tz": -60
    },
    "id": "ZMdIcS4my8Ks",
    "outputId": "ab7f1452-a68d-493f-bbe9-c2c8aa511b56",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This creates a csv file of nodes for Network3\n",
    "hashtag_nodes = uh_df.copy()\n",
    "hashtag_nodes[\"Label\"] = hashtag_nodes[\"Hashtag\"]\n",
    "hashtag_nodes.rename(columns={\"Hashtag\": \"Id\"}, inplace=True)\n",
    "hashtag_nodes = hashtag_nodes.drop(columns=['Count'])\n",
    "hashtag_nodes\n",
    "hashtag_nodes.to_csv(\"hashtag_nodelist_trans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHZHIG18ye0F"
   },
   "source": [
    "#### SAVE NODELIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpE0P0cIU2OD"
   },
   "outputs": [],
   "source": [
    "# This joins the two nodelists above and creates a csv file of nodes for Network1\n",
    "nodelist = hashtag_nodes.append(word_nodes, ignore_index=True)\n",
    "nodelist\n",
    "nodelist.to_csv(\"network_nodelist_trans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryR3LiMVB-70"
   },
   "source": [
    "Tasks: \n",
    "\n",
    "*   Extract username of user who posted the tweet into a column \"screen_name\". Follow the procedure we used to get the hashtags.\n",
    "*   Create a network of users using the mention relation. Is this a directed or undirected graph?\n",
    "*   We created a network where nodes are mixed (both words and hashtags). Create network of words only and one of hashtags only.\n",
    "* Pick one of these network and rank the nodes using PageRank centrality. Extract information about top-20 rated nodes.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PROJECT.ipynb adlƒ± not defterinin kopyasƒ±",
   "provenance": [
    {
     "file_id": "11joAJSU6DiU66i_fPfZpwD1P99GVFmiN",
     "timestamp": 1640290795210
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}